{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classification ###\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica'] # 0, 1, 2 categorical\n",
    "# Lets define some constants to help us later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "# Here we use keras (a module inside of TensorFlow) to grab our datasets and read them into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          6.4         2.8          5.6         2.2        2\n",
       "1          5.0         2.3          3.3         1.0        1\n",
       "2          4.9         2.5          4.5         1.7        2\n",
       "3          4.9         3.1          1.5         0.1        0\n",
       "4          5.7         3.8          1.7         0.3        0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          6.4         2.8          5.6         2.2\n",
       "1          5.0         2.3          3.3         1.0\n",
       "2          4.9         2.5          4.5         1.7\n",
       "3          4.9         3.1          1.5         0.1\n",
       "4          5.7         3.8          1.7         0.3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "# pop the response variable\n",
    "train.head() # compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "# feature columns describe how to use the input\n",
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "print(my_feature_columns)\n",
    "# could have looped through CSV_COLUMN_NAMES minus 'Species'\n",
    "# we did not have to do two loops for numeric and categorical variables...\n",
    "# ..separately, like in linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\BRADWA~1\\AppData\\Local\\Temp\\tmprs_ftgkc\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\BRADWA~1\\\\AppData\\\\Local\\\\Temp\\\\tmprs_ftgkc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Choose a pre-built model type in Tensorflow\n",
    "# DNNClassifier (Deep Neural Network)\n",
    "# LinearClassifier\n",
    "\n",
    "# *(!)* DNN may be best because we may not find linear correspondence...\n",
    "# ...within our data (training).\n",
    "# Note - a lot of the work comes in pre-processing data, rather than picking...\n",
    "# ...the right model to use. So it will be easy to change models, since the data...\n",
    "# ...is already prep'd.\n",
    "\n",
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 30 and 10 nodes respectively.\n",
    "    hidden_units=[30, 10],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python\\Anaconda3\\envs\\isye6501\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Python\\Anaconda3\\envs\\isye6501\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Python\\Anaconda3\\envs\\isye6501\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\adagrad.py:103: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\BRADWA~1\\AppData\\Local\\Temp\\tmprs_ftgkc\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.154932, step = 0\n",
      "INFO:tensorflow:global_step/sec: 324.465\n",
      "INFO:tensorflow:loss = 0.84939176, step = 100 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.687\n",
      "INFO:tensorflow:loss = 0.78091896, step = 200 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.64\n",
      "INFO:tensorflow:loss = 0.7364159, step = 300 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.462\n",
      "INFO:tensorflow:loss = 0.7102752, step = 400 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.396\n",
      "INFO:tensorflow:loss = 0.674513, step = 500 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 397\n",
      "INFO:tensorflow:loss = 0.6559101, step = 600 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.684\n",
      "INFO:tensorflow:loss = 0.6331108, step = 700 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.65\n",
      "INFO:tensorflow:loss = 0.61402154, step = 800 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.319\n",
      "INFO:tensorflow:loss = 0.5949144, step = 900 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.322\n",
      "INFO:tensorflow:loss = 0.5856974, step = 1000 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.4\n",
      "INFO:tensorflow:loss = 0.55986625, step = 1100 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.766\n",
      "INFO:tensorflow:loss = 0.5460814, step = 1200 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.277\n",
      "INFO:tensorflow:loss = 0.5255785, step = 1300 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.791\n",
      "INFO:tensorflow:loss = 0.51720405, step = 1400 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.404\n",
      "INFO:tensorflow:loss = 0.50924695, step = 1500 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.612\n",
      "INFO:tensorflow:loss = 0.5078916, step = 1600 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.869\n",
      "INFO:tensorflow:loss = 0.49384466, step = 1700 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.379\n",
      "INFO:tensorflow:loss = 0.48796046, step = 1800 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.672\n",
      "INFO:tensorflow:loss = 0.4705139, step = 1900 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.311\n",
      "INFO:tensorflow:loss = 0.47066897, step = 2000 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.814\n",
      "INFO:tensorflow:loss = 0.4559759, step = 2100 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.299\n",
      "INFO:tensorflow:loss = 0.4502473, step = 2200 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.125\n",
      "INFO:tensorflow:loss = 0.44399083, step = 2300 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.942\n",
      "INFO:tensorflow:loss = 0.4423789, step = 2400 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.689\n",
      "INFO:tensorflow:loss = 0.43161678, step = 2500 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.874\n",
      "INFO:tensorflow:loss = 0.42665893, step = 2600 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.107\n",
      "INFO:tensorflow:loss = 0.41717535, step = 2700 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.848\n",
      "INFO:tensorflow:loss = 0.4157259, step = 2800 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.274\n",
      "INFO:tensorflow:loss = 0.41640842, step = 2900 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.082\n",
      "INFO:tensorflow:loss = 0.39651075, step = 3000 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.636\n",
      "INFO:tensorflow:loss = 0.3969848, step = 3100 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.311\n",
      "INFO:tensorflow:loss = 0.38388467, step = 3200 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.657\n",
      "INFO:tensorflow:loss = 0.38819206, step = 3300 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.681\n",
      "INFO:tensorflow:loss = 0.37180847, step = 3400 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.681\n",
      "INFO:tensorflow:loss = 0.37009233, step = 3500 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.26\n",
      "INFO:tensorflow:loss = 0.3541916, step = 3600 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.021\n",
      "INFO:tensorflow:loss = 0.3483755, step = 3700 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.801\n",
      "INFO:tensorflow:loss = 0.33147603, step = 3800 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.75\n",
      "INFO:tensorflow:loss = 0.33540267, step = 3900 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.807\n",
      "INFO:tensorflow:loss = 0.33065885, step = 4000 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.419\n",
      "INFO:tensorflow:loss = 0.32437027, step = 4100 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.029\n",
      "INFO:tensorflow:loss = 0.31782016, step = 4200 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.959\n",
      "INFO:tensorflow:loss = 0.312806, step = 4300 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.716\n",
      "INFO:tensorflow:loss = 0.30818635, step = 4400 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.48\n",
      "INFO:tensorflow:loss = 0.31039023, step = 4500 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.432\n",
      "INFO:tensorflow:loss = 0.30641526, step = 4600 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.809\n",
      "INFO:tensorflow:loss = 0.29708073, step = 4700 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.329\n",
      "INFO:tensorflow:loss = 0.29900908, step = 4800 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.017\n",
      "INFO:tensorflow:loss = 0.28874385, step = 4900 (0.243 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\BRADWA~1\\AppData\\Local\\Temp\\tmprs_ftgkc\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.29600638.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x1460368b848>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    steps=5000)\n",
    "# We include a lambda to avoid creating an inner function previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-01-01T23:07:40Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\BRADWA~1\\AppData\\Local\\Temp\\tmprs_ftgkc\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.54826s\n",
      "INFO:tensorflow:Finished evaluation at 2021-01-01-23:07:40\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.96666664, average_loss = 0.33454758, global_step = 5000, loss = 0.33454758\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: C:\\Users\\BRADWA~1\\AppData\\Local\\Temp\\tmprs_ftgkc\\model.ckpt-5000\n",
      "\n",
      "Test set accuracy: 0.967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type numeric values as prompted.\n",
      "SepalLength: 1.5\n",
      "SepalWidth: 1.5\n",
      "PetalLength: 1.2\n",
      "PetalWidth: 2.1\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\BRADWA~1\\AppData\\Local\\Temp\\tmprs_ftgkc\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "{'logits': array([-0.59735596, -0.32982424,  0.81987756], dtype=float32), 'probabilities': array([0.15546235, 0.2031481 , 0.6413896 ], dtype=float32), 'class_ids': array([2], dtype=int64), 'classes': array([b'2'], dtype=object), 'all_class_ids': array([0, 1, 2]), 'all_classes': array([b'0', b'1', b'2'], dtype=object)}\n",
      "Prediction is \"Virginica\" at 64.1%\n"
     ]
    }
   ],
   "source": [
    "def input_fn(features, batch_size=256):\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "#features = list(train.keys())\n",
    "predict = {} # populate with keys:values and pass to input_fn(X) call\n",
    "\n",
    "print(\"Please type numeric values as prompted.\")\n",
    "for feature in features:\n",
    "  valid = True\n",
    "  while valid: \n",
    "    val = input(feature + \": \")\n",
    "    if not val.isdigit(): valid = False\n",
    "\n",
    "  predict[feature] = [float(val)]\n",
    "\n",
    "predictions = classifier.predict(input_fn=lambda: input_fn(predict))\n",
    "#predictions returns a object that needs to be unpacked\n",
    "for pred_dict in predictions:\n",
    "    print(pred_dict)\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" at {:.1f}%'.format(\n",
    "        SPECIES[class_id], 100 * probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is some example input and expected classes you can try above\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clustering ###\n",
    "#Now that we've covered regression and classification it's time to talk about clustering data!\n",
    "\n",
    "#Clustering is a Machine Learning technique that involves the grouping of data points. \n",
    "#In theory, data points that are in the same group should have similar properties and/or features, \n",
    "#while data points in different groups should have highly dissimilar properties and/or features. \n",
    "#(https://towardsdatascience.com/the-5-clustering-algorithms-data-scientists-need-to-know-a36d136ef68)\n",
    "\n",
    "#Unfortunalty there are issues with the current version of TensorFlow and the implementation for KMeans. \n",
    "#This means we cannot use KMeans without writing the algorithm from scratch. \n",
    "#We aren't quite at that level yet, so we'll just explain the basics of clustering for now.\n",
    "\n",
    "#Basic Algorithm for K-Means.\n",
    "\n",
    "#    Step 1: Randomly pick K points to place K centroids\n",
    "#    Step 2: Assign all the data points to the centroids by distance. The closest centroid to a point is the one it is assigned to.\n",
    "#    Step 3: Average all the points belonging to each centroid to find the middle of those clusters (center of mass). Place the corresponding centroids into that position.\n",
    "#    Step 4: Reassign every point once again to the closest centroid.\n",
    "#    Step 5: Repeat steps 3-4 until no point changes which centroid it belongs to.\n",
    "\n",
    "#Please refer to the video for an explanation of KMeans clustering.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hidden Markov Models ###\n",
    "# \"The Hidden Markov Model is a finite set of states, each of which is associated with a (generally multidimensional) probability distribution []. \n",
    "#Transitions among the states are governed by a set of probabilities called transition probabilities.\" \n",
    "#http://jedlik.phy.bme.hu/~gerjanos/HMM/node4.html)\n",
    "\n",
    "# A hidden markov model works with probabilities to predict future events or states. \n",
    "#In this section we will learn how to create a hidden markov model that can predict the weather.\n",
    "\n",
    "# This section is based on the following TensorFlow tutorial. \n",
    "#https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/HiddenMarkovModel\n",
    "\n",
    "# np.linalg.solve(A,b)? \n",
    "\n",
    "#We can find these probabilities from large datasets or may already have these values. We'll run through an example in a second that should clear some things up, but let's discuss the components of a markov model.\n",
    "\n",
    "#States: In each markov model we have a finite set of states. These states could be something like \"warm\" and \"cold\" or \"high\" and \"low\" or even \"red\", \"green\" and \"blue\". These states are \"hidden\" within the model, which means we do not direcly observe them.\n",
    "\n",
    "#Observations: Each state has a particular outcome or observation associated with it based on a probability distribution. An example of this is the following: On a hot day Tim has a 80% chance of being happy and a 20% chance of being sad.\n",
    "\n",
    "#Transitions: Each state will have a probability defining the likelyhood of transitioning to a different state. An example is the following: a cold day has a 30% chance of being followed by a hot day and a 70% chance of being follwed by another cold day.\n",
    "\n",
    "#To create a hidden markov model we need.\n",
    "\n",
    "    #1. States\n",
    "    #2. Observation Distribution\n",
    "    #3. Transition Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from scipy.linalg import lu\n",
    "\n",
    "a = array([[0.7,0.3],[0.2,0.8]])\n",
    "\n",
    "pl, u = lu(a, permute_l=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7        0.3       ]\n",
      " [0.         0.71428571]]\n"
     ]
    }
   ],
   "source": [
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tensorflow Example - Markov ##\n",
    "\n",
    "import tensorflow_probability as tfp  # We are using a different module from tensorflow this time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cold days are encoded as 0, and hot days are encoded as 1\n",
    "# 2. The first day in our sequence has an 80% chance of being cold\n",
    "# ... i.e. [0.8, 0.2]\n",
    "# 3. A cold day has a 30% chance of being followed by a hot day, and therefore a 70% chance of remaining cold \n",
    "# ... i.e. 0 -> [0.7, 0.3]\n",
    "# 4. A hot day has a 20% chance of being followed by a cold day, and therefore a 80% chance of remaining hot \n",
    "# ... i.e. 1 -> [0.2, 0.8]\n",
    "# 5. On each day the temperature is normally distributed with mean and standard deviation 0 and 5 on a cold day \n",
    "# ... and mean and standard deviation 15 and 10 on a hot day.\n",
    "\n",
    "tfd = tfp.distributions # making a shortcut for later on (i.e. below)\n",
    "initial_dist = tfd.Categorical(probs=[0.2,0.8]) # refer point 2\n",
    "transition_dist = tfd.Categorical(probs=[[0.5, 0.5],\n",
    "                                        [0.2, 0.8]]) # refers to point 3 and 4\n",
    "observation_dist = tfd.Normal(loc=[0., 15.], scale=[5., 10.]) # refer to point 5 \n",
    "# in this case, loc = mean, scale = s.dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tfd.HiddenMarkovModel(\n",
    "    initial_distribution = initial_dist,\n",
    "    transition_distribution = transition_dist,\n",
    "    observation_distribution=observation_dist,\n",
    "        num_steps=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = model.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.       11.1      10.83     10.748999 10.724698 10.71741  10.715222\n",
      " 10.714567 10.71437  10.71431  10.714293 10.714288 10.714285 10.714285\n",
      " 10.714285 10.714285 10.714285 10.714285 10.714285 10.714285 10.714285]\n",
      "tf.Tensor(\n",
      "[12.       11.1      10.83     10.748999 10.724698 10.71741  10.715222\n",
      " 10.714567 10.71437  10.71431  10.714293 10.714288 10.714285 10.714285\n",
      " 10.714285 10.714285 10.714285 10.714285 10.714285 10.714285 10.714285], shape=(21,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:  \n",
    "    print(mean.numpy())\n",
    "print(mean)\n",
    "\n",
    "# Notice the convergence to a constant temperature. This is because the Markov model converges to a steady-state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
