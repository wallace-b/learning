{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e1da3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46167c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74fa267f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jul  1 22:09:59 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 532.03                 Driver Version: 532.03       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080       WDDM | 00000000:0A:00.0  On |                  N/A |\n",
      "|  0%   44C    P8               41W / 390W|    849MiB / 12288MiB |     18%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      4924    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A      5676    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      7824    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe    N/A      |\n",
      "|    0   N/A  N/A     13132    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     18244    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     19680    C+G   ...64__8wekyb3d8bbwe\\CalculatorApp.exe    N/A      |\n",
      "|    0   N/A  N/A     19720    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     20100    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     20612    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     22404    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     23376    C+G   ...03.0_x64__8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
      "|    0   N/A  N/A     23416    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe    N/A      |\n",
      "|    0   N/A  N/A     23900    C+G   ...B\\system_tray\\lghub_system_tray.exe    N/A      |\n",
      "|    0   N/A  N/A     24052    C+G   C:\\Program Files\\LGHUB\\lghub.exe          N/A      |\n",
      "|    0   N/A  N/A     25256    C+G   ...al\\Discord\\app-1.0.9013\\Discord.exe    N/A      |\n",
      "|    0   N/A  N/A     26148    C+G   ...l\\Microsoft\\Teams\\current\\Teams.exe    N/A      |\n",
      "|    0   N/A  N/A     27024    C+G   ...l\\Microsoft\\Teams\\current\\Teams.exe    N/A      |\n",
      "|    0   N/A  N/A     28212    C+G   ....0_x64__kzh8wxbdkxb8p\\DCv2\\DCv2.exe    N/A      |\n",
      "|    0   N/A  N/A     28796    C+G   ..._x64__kzf8qxf38zg5c\\Skype\\Skype.exe    N/A      |\n",
      "|    0   N/A  N/A     29152    C+G   ...amsung Magician\\SamsungMagician.exe    N/A      |\n",
      "|    0   N/A  N/A     30284    C+G   ...1.0_x64__8wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
      "|    0   N/A  N/A     34648    C+G   ..._8wekyb3d8bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c4f9129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bracket notation helps to define the dimensions of a tensor in PyTorch\n",
    "x = [[1, 2],[3, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b805b7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4964, 0.9329, 0.1361],\n",
      "        [0.5665, 0.2957, 0.0744],\n",
      "        [0.7036, 0.9525, 0.9620],\n",
      "        [0.5882, 0.5303, 0.5702],\n",
      "        [0.2858, 0.0828, 0.9421]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3) # rand{0,1} 5 rows, 3 columns\n",
    "print(x)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b54741a",
   "metadata": {},
   "source": [
    "### Why random tensors?\n",
    "Random tensors are important because many neural networks are initialized with random numbers, i.e. parameters weights and biases, and adjust these random numbers to better represent the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "332e366e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1280, 720]), 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of bracket notation and concept of a 3dim-tensor: 2D RGB image\n",
    "random_image_tensor = torch.rand(size=(3, 1280, 720)) # RGB color channel, height (pixel), width (pixel)\n",
    "random_image_tensor.shape, random_image_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e049b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display random image\n",
    "### Add code later ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "098c5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Syntax notes ##\n",
    "# torch.rand(X, Y, Z) == torch.rand(size=X, Y, Z), tensor of X * Y * Z dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42fe3506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros. \n",
    "zeros = torch.zeros(size=(3, 1280, 720))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144dea8a",
   "metadata": {},
   "source": [
    "### Notes - Zero tensors\n",
    "Zero tensors can function as a mask i.e. setting a column, row, etc, or the entire tensor of a target tensor to 0, using matrix mult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cecaad63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using zero tensor as a mask\n",
    "zeros*random_image_tensor # ... the same result as the zeros tensor above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d013313b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3, 1280, 720))\n",
    "ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b652059",
   "metadata": {},
   "source": [
    "### Notes - Random, Zeros and Ones tensors\n",
    "In practice, random tensors are used a lot, so are zeros tensor. Less commonly one tensors are used. But it stands to reason that Ones and Zeros tensors together could be use in conjunction to create manually masks for sparse solutions to a deep learning neural network, or to specify a neural network connectivity (graph) matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f22709b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
      "tensor([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100])\n"
     ]
    }
   ],
   "source": [
    "# Use torch.arange(start, end 'end-1 index', step)\n",
    "one_to_ten_tensor = torch.arange(1, 11)\n",
    "print(one_to_ten_tensor)\n",
    "ten_to_hundred_tensor = torch.arange(10, 101, 10) # == torch.arange(start=10, end=101, step=10)\n",
    "print(ten_to_hundred_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68285845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Creating tensors like e.g. zeros_like(input=X_tensor)\n",
    "ten_zeros_tensor = torch.zeros_like(one_to_ten_tensor)\n",
    "print(ten_zeros_tensor)\n",
    "print(one_to_ten_tensor.shape)\n",
    "print(ten_zeros_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bd09b24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]], device='cuda:0', dtype=torch.int16)\n",
      "torch.int16\n",
      "\n",
      "tensor([2, 4, 6, 8], device='cuda:0', dtype=torch.int16)\n",
      "torch.int16\n",
      "cuda:0\n",
      "\n",
      "tensor([2, 2, 4, 4], dtype=torch.int32)\n",
      "torch.int32\n",
      "cpu\n",
      "\n",
      "Attempt y2*y3. Should throw an error due to different devices.\n",
      "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! :O\n"
     ]
    }
   ],
   "source": [
    "# Tensor Datatypes\n",
    "y1 = torch.ones(5,3, dtype=torch.int16, device=\"cuda\")\n",
    "y2 = torch.tensor([2.0, 4.0, 6.0, 8.0], \n",
    "               dtype=torch.int16, # What datatype the tensor is\n",
    "               device=\"cuda\", # What device is the tensor on i.e. select device \"cpu\", \"gpu\", \"cuda\", and so on...\n",
    "               requires_grad=False) # Whether or not to track gradients with this tensor's operations\n",
    "y3 = torch.tensor([2.0, 2.0, 4.0, 4.0], \n",
    "               dtype=torch.int32,\n",
    "               device=\"cpu\",\n",
    "               requires_grad=False)\n",
    "print(y1)\n",
    "print(y1.dtype)\n",
    "print()\n",
    "print(y2)\n",
    "print(y2.dtype)\n",
    "print(y2.device)\n",
    "print()\n",
    "print(y3)\n",
    "print(y3.dtype)\n",
    "print(y3.device)\n",
    "print()\n",
    "print(\"Attempt y2*y3. Should throw an error due to different devices.\")\n",
    "try: print(y2*y3)\n",
    "except Exception as e: print(e, \":O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1127e306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 4., 6., 8.], device='cuda:0', dtype=torch.float64)\n",
      "torch.Size([4]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# Changing a datatype\n",
    "float_double_y2 = y2.type(torch.double) # == y2.type(torch.float64)\n",
    "print(float_double_y2)\n",
    "print(float_double_y2.shape, float_double_y2.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a116a048",
   "metadata": {},
   "source": [
    "### Notes - Tensor Data Types\n",
    "There are many torch datatypes. Torch tensors are strictly-typed like Numpy arrays.\n",
    "Refer to https://pytorch.org/docs/stable/tensors.html#torch-tensor for datatypes.\n",
    "Recall the level of precision or max-min trade-off for the bit-size a datatype requires\n",
    "Running a deep learning neural network on a smaller bit-size datatypes typically will be faster, so this embodies the precision vs. speed trade-off.\n",
    "\n",
    "\n",
    "### Common sources of errors (check tensor attributes)\n",
    "1. Tensors are not the correct/compatible datatype - check tensor.dtype\n",
    "2. Tensors are not the correct shape - check tensor.shape (== tensor.size(), a method)\n",
    "e.g. m x n * n x p shape required for matrix mult \n",
    "3. Tensors are not on the right device - check tensor.device\n",
    "e.g. one tensor is on the \"cpu\" and another is on the \"gpu\", and you attempt to perform a matrix operation between these two tensors "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a5c7ed",
   "metadata": {},
   "source": [
    "## Manipulating Tensors (Tensor operations)\n",
    "Tensor operations include:\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Multiplication (element-wise)\n",
    "* Division\n",
    "* Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "97f232fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000]], device='cuda:0')\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Basic matrix operations\n",
    "z = y1 - 0.5\n",
    "print(z)\n",
    "print((z - 0.5) * 2) # scale to -1 and 1 from {0,1} range \n",
    "#i.e. 0.5 on the range {0, 1} changes to 0 in range {-1,1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fdd26459",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1157)\n",
    "t1 = torch.rand(3,3)\n",
    "t2 = torch.rand(3,3)\n",
    "t3 = torch.rand(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ef079826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0')\n",
      "tensor([[0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(2*z) # 2y : matrix*scalar\n",
    "print(2*z + z - z - z) # 2z - z : matrix addition/subtraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "32a6eba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " z: tensor([[0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000]], device='cuda:0')\n",
      "torch.Size([5, 3])\n",
      " t4: tensor([[7.3699e-01, 1.9177e-01, 1.7897e-01],\n",
      "        [1.8632e-01, 5.1089e-01, 9.2811e-01],\n",
      "        [3.8807e-01, 3.9561e-01, 6.9177e-01],\n",
      "        [5.3043e-04, 2.9116e-01, 6.7291e-01],\n",
      "        [2.4199e-01, 8.6214e-01, 8.2421e-01]], device='cuda:0')\n",
      "torch.Size([5, 3])\n",
      " t5: tensor([[0.4517, 0.2861, 0.8093, 0.7285, 0.9133],\n",
      "        [0.3703, 0.2577, 0.7517, 0.5376, 0.6788],\n",
      "        [0.6276, 0.5184, 0.7784, 0.8563, 0.1986]], device='cuda:0')\n",
      "torch.Size([3, 5])\n",
      " element-wise mult, z * t4: tensor([[3.6849e-01, 9.5883e-02, 8.9483e-02],\n",
      "        [9.3158e-02, 2.5545e-01, 4.6406e-01],\n",
      "        [1.9403e-01, 1.9781e-01, 3.4589e-01],\n",
      "        [2.6522e-04, 1.4558e-01, 3.3645e-01],\n",
      "        [1.2100e-01, 4.3107e-01, 4.1210e-01]], device='cuda:0')\n",
      "element-wise mult simply halves the entries of t4 because z is 0.5 in all entries\n",
      " mat-mult (dot product) z * t5: tensor([[0.7248, 0.5311, 1.1697, 1.0612, 0.8954],\n",
      "        [0.7248, 0.5311, 1.1697, 1.0612, 0.8954],\n",
      "        [0.7248, 0.5311, 1.1697, 1.0612, 0.8954],\n",
      "        [0.7248, 0.5311, 1.1697, 1.0612, 0.8954],\n",
      "        [0.7248, 0.5311, 1.1697, 1.0612, 0.8954]], device='cuda:0')\n",
      "matrix multiplication (dot product) performs, in a 2D case, a row by col element-wise mult then summation ... \n",
      "... for each entry in the result. E.g. the 1,1 entry is the element-wise multiplication and summation of...\n",
      "... the first row of the first tensor and the first column of the second tensor.\n"
     ]
    }
   ],
   "source": [
    "print(f\" z: {z}\")\n",
    "print(z.shape)\n",
    "t4 = torch.rand(5,3, device=\"cuda\")\n",
    "print(f\" t4: {t4}\")\n",
    "print(t4.shape)\n",
    "t5 = torch.rand(3,5, device=\"cuda\")\n",
    "print(f\" t5: {t5}\")\n",
    "print(t5.shape)\n",
    "print(f\" element-wise mult, z * t4: {z * t4}\")\n",
    "print(\"element-wise mult simply halves the entries of t4 because z is 0.5 in all entries\")\n",
    "print(f\" mat-mult (dot product) z * t5: {torch.matmul(z, t5)}\")\n",
    "print(\"matrix multiplication (dot product) performs, in a 2D case, a row by col element-wise mult then summation ... \")\n",
    "print(\"... for each entry in the result. E.g. the 1,1 entry is the element-wise multiplication and summation of...\")\n",
    "print(\"... the first row of the first tensor and the first column of the second tensor.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "76c0ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_a = z\n",
    "tensor_b = t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cc370638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.7248, 0.5311, 1.1697, 1.0612, 0.8954],\n",
       "        [0.7248, 0.5311, 1.1697, 1.0612, 0.8954],\n",
       "        [0.7248, 0.5311, 1.1697, 1.0612, 0.8954],\n",
       "        [0.7248, 0.5311, 1.1697, 1.0612, 0.8954],\n",
       "        [0.7248, 0.5311, 1.1697, 1.0612, 0.8954]], device='cuda:0')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 0ns\n",
    "#torch.matmul(tensor_a, tensor_b) == torch.mm(tensor_a, tensor_b) shorthand version\n",
    "torch.mm(tensor_a, tensor_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "65fff97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 4.04 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.7248, 0.5311, 1.1697, 1.0612, 0.8954],\n",
       "        [0.7248, 0.5311, 1.1697, 1.0612, 0.8954],\n",
       "        [0.7248, 0.5311, 1.1697, 1.0612, 0.8954],\n",
       "        [0.7248, 0.5311, 1.1697, 1.0612, 0.8954],\n",
       "        [0.7248, 0.5311, 1.1697, 1.0612, 0.8954]], device='cuda:0')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    " # 3.5~4.0ms using cuda\n",
    "# final shape is m x n * n * p => m * p\n",
    "res_m_rows = tensor_a.shape[0]\n",
    "res_p_cols = tensor_b.shape[1]\n",
    "\n",
    "output_tensor = torch.empty((res_m_rows, res_p_cols), device=\"cuda\") \n",
    "# create an empty tensor of m * p dimensions for manual 2D matrix multiplication\n",
    "# print(output_tensor.shape) torch.Size([5, 5])\n",
    "\n",
    "for i, row_i in enumerate(tensor_a):\n",
    "    temp_list_ = [] \n",
    "    # temporary list (a row in the final tensor) to store sums of element-wise row_i * col_j for each i,j combination\n",
    "    for j, col_j in enumerate(torch.t(tensor_b)): \n",
    "        # uses transpose (torch.t) to flip the orientation of tensor_b i.e. rows -> cols, cols -> rows ...\n",
    "        # ... 'for' loops over the first indexing major i.e. rows in Python by default (C: row-major). \n",
    "        # There are packages and methods that use Fortran-major (F: col major) and loop over cols by default.    \n",
    "        val_ = torch.sum(row_i*col_j).item()\n",
    "        # uses torch.sum to sum the individual element-wise multiplications of the elements from row_i * col_j\n",
    "        temp_list_.append(val_) # append each sum to the temporary list\n",
    "    if (len(temp_list_)==res_p_cols):\n",
    "        output_tensor[i,:] = torch.tensor(temp_list_, device=\"cuda\") \n",
    "        # convert temp list (a row) to tensor and insert into output tensor using row index (row i)\n",
    "    else: break # stop if temporary list is of wrong dimension\n",
    "        \n",
    "output_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d783a99d",
   "metadata": {},
   "source": [
    "### Other Tensor functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "33a0db3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A random matrix, r:\n",
      "tensor([[ 0.4462, -0.6505,  0.2924],\n",
      "        [ 0.3684, -0.4274, -0.1105],\n",
      "        [-0.0149,  0.2337, -0.7636]])\n",
      "\n",
      "Absolute value of r:\n",
      "tensor([[0.4462, 0.6505, 0.2924],\n",
      "        [0.3684, 0.4274, 0.1105],\n",
      "        [0.0149, 0.2337, 0.7636]])\n",
      "\n",
      "Inverse sine of r:\n",
      "tensor([[ 0.4625, -0.7082,  0.2967],\n",
      "        [ 0.3773, -0.4416, -0.1107],\n",
      "        [-0.0149,  0.2359, -0.8688]])\n",
      "\n",
      "Determinant of r:\n",
      "tensor(-0.0037)\n",
      "\n",
      "Singular value decomposition of r:\n",
      "torch.return_types.svd(\n",
      "U=tensor([[-0.7536, -0.2654,  0.6014],\n",
      "        [-0.3748, -0.5782, -0.7247],\n",
      "        [ 0.5401, -0.7715,  0.3362]]),\n",
      "S=tensor([1.0887, 0.7005, 0.0048]),\n",
      "V=tensor([[-0.4430, -0.4566, -0.7715],\n",
      "        [ 0.7133,  0.3418, -0.6119],\n",
      "        [-0.5431,  0.8214, -0.1743]]))\n",
      "\n",
      "Average and standard deviation of r:\n",
      "(tensor(0.4517), tensor(-0.0696))\n",
      "\n",
      "Maximum value of r:\n",
      "tensor(0.4462)\n"
     ]
    }
   ],
   "source": [
    "u = (torch.rand(3, 3) - 0.5) * 2 # scale values between -1 and 1\n",
    "print('A random matrix, r:')\n",
    "print(u)\n",
    "\n",
    "# Common mathematical operations are supported:\n",
    "print('\\nAbsolute value of r:')\n",
    "print(torch.abs(u))\n",
    "\n",
    "# ...as are trigonometric functions:\n",
    "print('\\nInverse sine of r:')\n",
    "print(torch.asin(u))\n",
    "\n",
    "# ...and linear algebra operations like determinant and singular value decomposition\n",
    "print('\\nDeterminant of r:')\n",
    "print(torch.det(u))\n",
    "print('\\nSingular value decomposition of r:')\n",
    "print(torch.svd(u))\n",
    "\n",
    "# ...and statistical and aggregate operations:\n",
    "print('\\nAverage and standard deviation of r:')\n",
    "print(torch.std_mean(u))\n",
    "print('\\nMaximum value of r:')\n",
    "print(torch.max(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83d8a15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
