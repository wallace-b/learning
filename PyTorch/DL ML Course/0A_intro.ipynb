{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e1da3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46167c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74fa267f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 28 22:21:26 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 532.03                 Driver Version: 532.03       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080       WDDM | 00000000:0A:00.0  On |                  N/A |\n",
      "|  0%   48C    P8               43W / 390W|    823MiB / 12288MiB |     14%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      4880    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A     11684    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     12184    C+G   ...amsung Magician\\SamsungMagician.exe    N/A      |\n",
      "|    0   N/A  N/A     17112    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     17528    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     18416    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     19640    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe    N/A      |\n",
      "|    0   N/A  N/A     22244    C+G   ...1.0_x64__8wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
      "|    0   N/A  N/A     23960    C+G   ...B\\system_tray\\lghub_system_tray.exe    N/A      |\n",
      "|    0   N/A  N/A     24144    C+G   C:\\Program Files\\LGHUB\\lghub.exe          N/A      |\n",
      "|    0   N/A  N/A     24300    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     25556    C+G   ...al\\Discord\\app-1.0.9013\\Discord.exe    N/A      |\n",
      "|    0   N/A  N/A     25760    C+G   ...l\\Microsoft\\Teams\\current\\Teams.exe    N/A      |\n",
      "|    0   N/A  N/A     26100    C+G   ...64__8wekyb3d8bbwe\\CalculatorApp.exe    N/A      |\n",
      "|    0   N/A  N/A     26232    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe    N/A      |\n",
      "|    0   N/A  N/A     26812    C+G   ...03.0_x64__8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
      "|    0   N/A  N/A     28268    C+G   ...l\\Microsoft\\Teams\\current\\Teams.exe    N/A      |\n",
      "|    0   N/A  N/A     28552    C+G   ....0_x64__kzh8wxbdkxb8p\\DCv2\\DCv2.exe    N/A      |\n",
      "|    0   N/A  N/A     28788    C+G   ..._x64__kzf8qxf38zg5c\\Skype\\Skype.exe    N/A      |\n",
      "|    0   N/A  N/A     29008    C+G   ..._8wekyb3d8bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A     30132    C+G   ...Cloudflare WARP\\Cloudflare WARP.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c4f9129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bracket notation helps to define the dimensions of a tensor in PyTorch\n",
    "x = [[1, 2],[3, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b805b7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5806, 0.8816, 0.8396],\n",
      "        [0.1085, 0.0811, 0.8160],\n",
      "        [0.9973, 0.8089, 0.7146],\n",
      "        [0.0777, 0.6050, 0.0897],\n",
      "        [0.3662, 0.8368, 0.4188]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3) # rand{0,1} 5 rows, 3 columns\n",
    "print(x)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b54741a",
   "metadata": {},
   "source": [
    "### Why random tensors?\n",
    "Random tensors are important because many neural networks are initialized with random numbers, i.e. parameters weights and biases, and adjust these random numbers to better represent the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "332e366e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1280, 720]), 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of bracket notation and concept of a 3dim-tensor: 2D RGB image\n",
    "random_image_tensor = torch.rand(size=(3, 1280, 720)) # RGB color channel, height (pixel), width (pixel)\n",
    "random_image_tensor.shape, random_image_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e049b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display random image\n",
    "### Add code later ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "098c5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Syntax notes ##\n",
    "# torch.rand(X, Y, Z) == torch.rand(size=X, Y, Z), tensor of X * Y * Z dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42fe3506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros. \n",
    "zeros = torch.zeros(size=(3, 1280, 720))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144dea8a",
   "metadata": {},
   "source": [
    "### Notes - Zero tensors\n",
    "Zero tensors can function as a mask i.e. setting a column, row, etc, or the entire tensor of a target tensor to 0, using matrix mult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cecaad63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using zero tensor as a mask\n",
    "zeros*random_image_tensor # ... the same result as the zeros tensor above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d013313b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3, 1280, 720))\n",
    "ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b652059",
   "metadata": {},
   "source": [
    "### Notes - Random, Zeros and Ones tensors\n",
    "In practice, random tensors are used a lot, so are zeros tensor. Less commonly one tensors are used. But it stands to reason that Ones and Zeros tensors together could be use in conjunction to create manually masks for sparse solutions to a deep learning neural network, or to specify a neural network connectivity (graph) matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f22709b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
      "tensor([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100])\n"
     ]
    }
   ],
   "source": [
    "# Use torch.arange(start, end 'end-1 index', step)\n",
    "one_to_ten_tensor = torch.arange(1, 11)\n",
    "print(one_to_ten_tensor)\n",
    "ten_to_hundred_tensor = torch.arange(10, 101, 10) # == torch.arange(start=10, end=101, step=10)\n",
    "print(ten_to_hundred_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68285845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Creating tensors like e.g. zeros_like(input=X_tensor)\n",
    "ten_zeros_tensor = torch.zeros_like(one_to_ten_tensor)\n",
    "print(ten_zeros_tensor)\n",
    "print(one_to_ten_tensor.shape)\n",
    "print(ten_zeros_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd09b24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int16)\n",
      "torch.int16\n",
      "\n",
      "tensor([2, 4, 6, 8], device='cuda:0', dtype=torch.int16)\n",
      "torch.int16\n",
      "cuda:0\n",
      "\n",
      "tensor([2, 2, 4, 4], dtype=torch.int32)\n",
      "torch.int32\n",
      "cpu\n",
      "\n",
      "Attempt y2*y3. Should throw an error due to different devices.\n",
      "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! :O\n"
     ]
    }
   ],
   "source": [
    "# Tensor Datatypes\n",
    "y1 = torch.ones(5,3, dtype=torch.int16)\n",
    "y2 = torch.tensor([2.0, 4.0, 6.0, 8.0], \n",
    "               dtype=torch.int16, # What datatype the tensor is\n",
    "               device=\"cuda\", # What device is the tensor on i.e. select device \"cpu\", \"gpu\", \"cuda\", and so on...\n",
    "               requires_grad=False) # Whether or not to track gradients with this tensor's operations\n",
    "y3 = torch.tensor([2.0, 2.0, 4.0, 4.0], \n",
    "               dtype=torch.int32,\n",
    "               device=\"cpu\",\n",
    "               requires_grad=False)\n",
    "print(y1)\n",
    "print(y1.dtype)\n",
    "print()\n",
    "print(y2)\n",
    "print(y2.dtype)\n",
    "print(y2.device)\n",
    "print()\n",
    "print(y3)\n",
    "print(y3.dtype)\n",
    "print(y3.device)\n",
    "print()\n",
    "print(\"Attempt y2*y3. Should throw an error due to different devices.\")\n",
    "try: print(y2*y3)\n",
    "except Exception as e: print(e, \":O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1127e306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 4., 6., 8.], device='cuda:0', dtype=torch.float64)\n",
      "torch.Size([4]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# Changing a datatype\n",
    "float_double_y2 = y2.type(torch.double) # == y2.type(torch.float64)\n",
    "print(float_double_y2)\n",
    "print(float_double_y2.shape, float_double_y2.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a116a048",
   "metadata": {},
   "source": [
    "### Notes - Tensor Data Types\n",
    "There are many torch datatypes. Torch tensors are strictly-typed like Numpy arrays.\n",
    "Refer to https://pytorch.org/docs/stable/tensors.html#torch-tensor for datatypes.\n",
    "Recall the level of precision or max-min trade-off for the bit-size a datatype requires\n",
    "Running a deep learning neural network on a smaller bit-size datatypes typically will be faster, so this embodies the precision vs. speed trade-off.\n",
    "\n",
    "\n",
    "### Common sources of errors (check tensor attributes)\n",
    "1. Tensors are not the correct/compatible datatype - check tensor.dtype\n",
    "2. Tensors are not the correct shape - check tensor.shape (== tensor.size(), a method)\n",
    "e.g. m x n * n x p shape required for matrix mult \n",
    "3. Tensors are not on the right device - check tensor.device\n",
    "e.g. one tensor is on the \"cpu\" and another is on the \"gpu\", and you attempt to perform a matrix operation between these two tensors "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a5c7ed",
   "metadata": {},
   "source": [
    "## Manipulating Tensors (Tensor operations)\n",
    "Tensor operations include:\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Multiplication (element-wise)\n",
    "* Division\n",
    "* Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "97f232fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Basic matrix operations\n",
    "z = y - 0.5\n",
    "print(z)\n",
    "print((z - 0.5) * 2) # scale to -1 and 1 from {0,1} range \n",
    "#i.e. 0.5 on the range {0, 1} changes to 0 in range {-1,1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fdd26459",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1157)\n",
    "t1 = torch.rand(3,3)\n",
    "t2 = torch.rand(3,3)\n",
    "t3 = torch.rand(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef079826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 2, 2],\n",
      "        [2, 2, 2],\n",
      "        [2, 2, 2],\n",
      "        [2, 2, 2],\n",
      "        [2, 2, 2]], dtype=torch.int16)\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "print(2*z) # 2y : matrix*scalar\n",
    "print(2*z + z - z - z) # 2z - z : matrix addition/subtraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "32a6eba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " z: tensor([[0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000]])\n",
      "torch.Size([5, 3])\n",
      " t4: tensor([[0.2693, 0.9987, 0.4954],\n",
      "        [0.5404, 0.8359, 0.7370],\n",
      "        [0.8326, 0.0146, 0.3511],\n",
      "        [0.9076, 0.2586, 0.2114],\n",
      "        [0.9079, 0.0068, 0.7574]])\n",
      "torch.Size([5, 3])\n",
      " t5: tensor([[0.1269, 0.9468, 0.3391, 0.8739, 0.3752],\n",
      "        [0.9810, 0.8429, 0.3275, 0.1366, 0.8235],\n",
      "        [0.7632, 0.1902, 0.6937, 0.6986, 0.6828]])\n",
      "torch.Size([3, 5])\n",
      " element-wise mult, z * t4: tensor([[0.1346, 0.4993, 0.2477],\n",
      "        [0.2702, 0.4179, 0.3685],\n",
      "        [0.4163, 0.0073, 0.1756],\n",
      "        [0.4538, 0.1293, 0.1057],\n",
      "        [0.4539, 0.0034, 0.3787]])\n",
      "element-wise mult simply halves the entries of t4 because z is 0.5 in all entries\n",
      " mat-mult (dot product) z * t5: tensor([[0.9356, 0.9899, 0.6802, 0.8546, 0.9408],\n",
      "        [0.9356, 0.9899, 0.6802, 0.8546, 0.9408],\n",
      "        [0.9356, 0.9899, 0.6802, 0.8546, 0.9408],\n",
      "        [0.9356, 0.9899, 0.6802, 0.8546, 0.9408],\n",
      "        [0.9356, 0.9899, 0.6802, 0.8546, 0.9408]])\n",
      "matrix multiplication (dot product) performs, in a 2D case, a row by col element-wise mult then summation ... \n",
      "... for each entry in the result. E.g. the 1,1 entry is the element-wise multiplication and summation of...\n",
      "... the first row of the first tensor and the first column of the second tensor.\n"
     ]
    }
   ],
   "source": [
    "print(f\" z: {z}\")\n",
    "print(z.shape)\n",
    "t4 = torch.rand(5,3)\n",
    "print(f\" t4: {t4}\")\n",
    "print(t4.shape)\n",
    "t5 = torch.rand(3,5)\n",
    "print(f\" t5: {t5}\")\n",
    "print(t5.shape)\n",
    "print(f\" element-wise mult, z * t4: {z * t4}\")\n",
    "print(\"element-wise mult simply halves the entries of t4 because z is 0.5 in all entries\")\n",
    "print(f\" mat-mult (dot product) z * t5: {torch.matmul(z, t5)}\")\n",
    "print(\"matrix multiplication (dot product) performs, in a 2D case, a row by col element-wise mult then summation ... \")\n",
    "print(\"... for each entry in the result. E.g. the 1,1 entry is the element-wise multiplication and summation of...\")\n",
    "print(\"... the first row of the first tensor and the first column of the second tensor.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "76c0ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_a = z\n",
    "tensor_b = t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cc370638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9356, 0.9899, 0.6802, 0.8546, 0.9408],\n",
       "        [0.9356, 0.9899, 0.6802, 0.8546, 0.9408],\n",
       "        [0.9356, 0.9899, 0.6802, 0.8546, 0.9408],\n",
       "        [0.9356, 0.9899, 0.6802, 0.8546, 0.9408],\n",
       "        [0.9356, 0.9899, 0.6802, 0.8546, 0.9408]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor_a, tensor_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "65fff97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9355508089065552\n",
      "0.9899342060089111\n",
      "0.6801728010177612\n",
      "0.8545556664466858\n",
      "0.9407556653022766\n",
      "0.9355508089065552\n",
      "0.9899342060089111\n",
      "0.6801728010177612\n",
      "0.8545556664466858\n",
      "0.9407556653022766\n",
      "0.9355508089065552\n",
      "0.9899342060089111\n",
      "0.6801728010177612\n",
      "0.8545556664466858\n",
      "0.9407556653022766\n",
      "0.9355508089065552\n",
      "0.9899342060089111\n",
      "0.6801728010177612\n",
      "0.8545556664466858\n",
      "0.9407556653022766\n",
      "0.9355508089065552\n",
      "0.9899342060089111\n",
      "0.6801728010177612\n",
      "0.8545556664466858\n",
      "0.9407556653022766\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 1.22 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#np_array = np.array([])\n",
    "for row_i in tensor_a:\n",
    "    for col_j in torch.t(tensor_b):\n",
    "        print((torch.sum(row_i*col_j).item()))\n",
    "#print(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "33a0db3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A random matrix, r:\n",
      "tensor([[-0.7493, -0.5483, -0.5114],\n",
      "        [-0.3329, -0.5414, -0.9961],\n",
      "        [-0.3848, -0.7838, -0.0341]])\n",
      "\n",
      "Absolute value of r:\n",
      "tensor([[0.7493, 0.5483, 0.5114],\n",
      "        [0.3329, 0.5414, 0.9961],\n",
      "        [0.3848, 0.7838, 0.0341]])\n",
      "\n",
      "Inverse sine of r:\n",
      "tensor([[-0.8469, -0.5803, -0.5368],\n",
      "        [-0.3394, -0.5721, -1.4824],\n",
      "        [-0.3950, -0.9008, -0.0341]])\n",
      "\n",
      "Determinant of r:\n",
      "tensor(0.3403)\n",
      "\n",
      "Singular value decomposition of r:\n",
      "torch.return_types.svd(\n",
      "U=tensor([[-0.6185,  0.1591, -0.7695],\n",
      "        [-0.6622, -0.6327,  0.4014],\n",
      "        [-0.4230,  0.7578,  0.4967]]),\n",
      "S=tensor([1.6604, 0.6545, 0.3132]),\n",
      "V=tensor([[ 0.5099, -0.3058,  0.8040],\n",
      "        [ 0.6199, -0.5174, -0.5899],\n",
      "        [ 0.5964,  0.7992, -0.0743]]))\n",
      "\n",
      "Average and standard deviation of r:\n",
      "(tensor(0.2817), tensor(-0.5425))\n",
      "\n",
      "Maximum value of r:\n",
      "tensor(-0.0341)\n"
     ]
    }
   ],
   "source": [
    "u = (torch.rand(3, 3) - 0.5) * 2 # scale values between -1 and 1\n",
    "print('A random matrix, r:')\n",
    "print(u)\n",
    "\n",
    "# Common mathematical operations are supported:\n",
    "print('\\nAbsolute value of r:')\n",
    "print(torch.abs(u))\n",
    "\n",
    "# ...as are trigonometric functions:\n",
    "print('\\nInverse sine of r:')\n",
    "print(torch.asin(u))\n",
    "\n",
    "# ...and linear algebra operations like determinant and singular value decomposition\n",
    "print('\\nDeterminant of r:')\n",
    "print(torch.det(u))\n",
    "print('\\nSingular value decomposition of r:')\n",
    "print(torch.svd(u))\n",
    "\n",
    "# ...and statistical and aggregate operations:\n",
    "print('\\nAverage and standard deviation of r:')\n",
    "print(torch.std_mean(u))\n",
    "print('\\nMaximum value of r:')\n",
    "print(torch.max(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223fb250",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
